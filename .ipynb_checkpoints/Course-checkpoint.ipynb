{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning terms and topics\n",
    "* Understanding what they mean\n",
    "* How they fit in to the overall deep learning framework\n",
    "* How certain topics are implemented in code\n",
    "    * Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is the practice of using algorithms to analyze data, learn from that data, and then make a determination or prediction about new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning vs. Traditional Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Analyzing the sentiment of a popular media outlet and classifying that sentiment as positive or negative\n",
    "* Traditional Programming approach\n",
    "    * The algorithm may first look for particular words associated with a negative or positive sentiment.\n",
    "    * With conditional statements, the algorithm would classify articles as positives or negatives based on the words that it knows are positive or negative.\n",
    "* Machine Learning approach\n",
    "    * The algorithm would analyze large amount of given media data and learn the features that classify what a negative article looks like versus a positive article.\n",
    "    * With what it has learned, the algorithm could then classify new articles as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning (DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers the most basic idea about what deep learning is and how it's used. More detailled concepts, terms and tools will be covered within the filed of deep learning.\n",
    "\n",
    "**Definition**\n",
    "* Deep learning is a subfield of machine learning that uses algorithms inspired by the structure and function of the brain neural network.\n",
    "* As a subfield of ML, DL is also algorithms that analyze data, learn from that data and then make a determination or prediction about new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning** occurs when your deep learning model learns and make inferences from data that has _already been labeled_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised Learning** occurs when the modellearns and makes inferences from _unlabelled_ data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeled vs. Unlabeled example**\n",
    "* Classify images of cats and dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks (ANNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks are deep learning models that are based on the structure of the brain's neural networks.\n",
    "* Artificial neural networks are used interchangeably with the terms\n",
    "    * Neural net\n",
    "    * Net\n",
    "    * Model\n",
    "* These networks are based on a collection of connected units called **artificial neuron**, or **neurons**.\n",
    "* Each connection between neurons can transmit a signal from one neuron to another.\n",
    "* The receiving neuron process the signal and signals downstream neurons connected to it.\n",
    "* Neurons are organized in layers\n",
    "    * Input layer\n",
    "    * Hidden layers\n",
    "    * Output layer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Senquential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers in an ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks are typically organized in layers. Different types of layers include:\n",
    "* Dense (or fully connected) Layers\n",
    "* Convolutional Layers\n",
    "* Pooling Layers\n",
    "* Recurrent Layers\n",
    "* Normalization Layers\n",
    "* Many others ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(5, input_shape=(3,), activation='relu'),\n",
    "    Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0,0,1])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24501503888>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = np.expand_dims(imageio.imread('NN.PNG'),0)\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an artifician neural network, the activation function of a neuron defines the output of that neuron given a set of inputs.\n",
    "* Biologically inspired by activity in our brains, where different neurons fire, or are _activated_, by different stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(5, input_shape=(3,), activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_shape=(3,)))\n",
    "model.add(Sctiviation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving an optimization problem\n",
    "* Optimizing weights\n",
    "    * with Stochastic Gradient Descent (SGD). On the example bellow we are using the optimizer 'Adam' which is a variation of SGD.\n",
    "* Objective: Minimize the loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation is optional. It is used to verify that with data on which the model hasn't been trained can still be classified correctly.\n",
    "\n",
    "If the validation loss and accuracy are way worste than for the test dataset. This means the model has been overfitted.\n",
    "\n",
    "We can either pass a complete new dataset to the model or use a given proportion of the test dataset that will only be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will use 20% of the dataset as validation set, else give a np array for specific dataset.\n",
    "model.fit(scaled_train_samples, train_labels, validation_split=0.20, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that a model is overfitted when it perfoms very well on the traning dataset but poorly on the validating dataset. To avoid this there are multiple possibilities:\n",
    "* Adding mode data to the training dataset\n",
    "* When mentioned above is not possible, use data augmentation -> edit some data to increase diversity (e.g. if all photos shows dogs going to the right, flip some so that they go to the left)\n",
    "* Reducing complexity of the ANN (reducing number of nodes or layers)\n",
    "* Use the dropout technic -> this will dropout some nodes during testing so that other nodes have to learn new features themself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that a model is underfitted when it perfoms poorly even on the training dataset. To avoid this there are multiple possibilities:\n",
    "* Adding more features to the training dataset\n",
    "* Increase complexity of the ANN (increasing number of nodes or layers)\n",
    "* Reduce dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Validate data are labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight, height\n",
    "train_samples = [[150, 67], [130, 60], [200, 65], [125, 52], [230, 72], [181, 70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: male\n",
    "# 1: female\n",
    "train_labels = [1, 1, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_samples, y=train_labels, batch_size=3, epochs=10, shuffle=true, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dataset are unlabeled.\n",
    "\n",
    "The model will try to find some structure from the data and extract features from it. \n",
    "Accuracy is not a metric we can use for unsupervised learning.\n",
    "Unsupervised learning is used by clustering algorithm, autoencoders, ...\n",
    "\n",
    "_Autoencoders_ is an ANN that takes an input and outputs a reconstruction of this output. This is used for example to _denoise_ an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised  Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some portion of the train dataset is labeled, the rest is unlabeled.\n",
    "\n",
    "First, we train a model on the labeled dataset until it performs well enougth. Then we predict the unlabeled daataset using out model assigning what we call a _psuedo-label_. Finally we train a model on the full dataset that is combining the labeled and the psuedo-labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the action of creating data based on an already existing data by applying a reasonable modification (image flip, rotate, crop, colors, ...). \n",
    "\n",
    "This is often used when having a dataset which is difficult to enlarge with new data or to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date labels are not used as strings. They are usualy numbers or vectors. One type of encoding that is widly used is One-hot encoding.\n",
    "\n",
    "_One-hot Encoding_ translforms labels into vectors of 0s and 1s. The length of these vectors is equal to the number of classes or category that ou model is espected to classify. For exmaple: cat or dot => [x, x]. If we add rabbit => [x, x, x].\n",
    "Each element of the vector is related to a class, this means, each cats will be labeled [1,0,0] and each dog [0,1,0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN are neural network mostly used for analysing images. Its hidden layers contains convolutional layers.\n",
    "\n",
    "Convolutional layers can detect patterns. For this we must define filters. The first filters are always simplier and detect basic forms (edge, circle, squares, ...). The more we progess in the network, the complexer it gets until it recognise specific features like dog faces, birds legs, ...\n",
    "\n",
    "The filters are built with matrix that are applied to each pixels of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying convolution to an image of 28x28 with a matrix of 3x3. The convolution cannot be made on the two last rows and column, therefore the result will be 26x26.\n",
    "\n",
    "This can be an issue in most cases. This is where Zero Padding is used.\n",
    "In our example, zero padding will add one row and column on each side of the image so that the resulting image is of same size than the input.\n",
    "The number of rows and columns added depends of course on the matrix size.\n",
    "\n",
    "There are two kind of padding:\n",
    "* \"valid\" -> no padding at all -> size will not be maintaines\n",
    "* \"same\" -> applies the padding before applying the filter -> size will be maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.convolutional import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_valid = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(20,20,3)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='valid'),\n",
    "    Conv2D(64, kernel_size=(5, 5), activation='relu', padding='valid'),\n",
    "    Conv2D(128, kernel_size=(7, 7), activation='relu', padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20, 20, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 18, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         401536    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 16386     \n",
      "=================================================================\n",
      "Total params: 473,890\n",
      "Trainable params: 473,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_valid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_valid = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(20,20,3)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(7, 7), activation='relu', padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 20, 20, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 20, 20, 128)       401536    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 102402    \n",
      "=================================================================\n",
      "Total params: 559,906\n",
      "Trainable params: 559,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_valid.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used for reducing computational loal, overfitting.\n",
    "\n",
    "For this, we must define a matrix size (e.g 2x2) and a stride value (e.g 2). By applying max pooling with those parameter to an image of 28x28 it will return an image of 14x14 where each pixel has the value oh the higher value found in the matrix during the convolution.\n",
    "\n",
    "Of course there are other types of pooling (like average pooling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.pooling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_valid = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(20,20,3)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "    Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 20, 20, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 20, 20, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 12802     \n",
      "=================================================================\n",
      "Total params: 68,770\n",
      "Trainable params: 68,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_valid.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forwardpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process of moving the data forward through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process executed at the end of each forwardpropagation. This is where the derivated of the result is calculated for each weight and applied to the model for the next epoch. The changes applied to the weight is the mean value of all changes required by all train data that were used during the epoch.\n",
    "\n",
    "For a more detailed explication on how backpropagation is working mathematically, please refere to those [videos from deeplizard](https://www.youtube.com/watch?v=xClK__CqZnQ&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=23)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing & Exploding Gradient Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanishing gradient is the case when the gradient with respect to weight in earlier layers in the network becomes very small which implies very small changes in the weight for early stages (e.g 0.29 to 0.2899999).\n",
    "\n",
    "Exploding gradient probleme is the opposite of the vanishing gradient problem -> the gradient with respect to weight in earlier layers in the network becomes very huge which implies very huge changes in the weight for early stages (e.g 0.29 to 1.87).\n",
    "\n",
    "Those problemes are part a more general problem: instable gradients. See nect section for an example of method that helps avoiding this issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we initialized our weight with random numbers. But with high numbers of inputs, the variance on the next node can be too high (for 250 inputs -> variance of 250 -> standart derivation of about 16 (sqrt(250))). This means, our activations function (like the sigmoid one) will only change a little as the total input weight will be very large.\n",
    "\n",
    "To avoid this situation we should multiply the initial weight values like this: w = w\\*sqrt(**1**/n) where n is the number of inputs. This is the **Xavier initialization** or **Glorot initialization** and can solve issues like Vanishing or Exploding gradients.\n",
    "\n",
    "If we are using **relu** as activation function (which is highly likely), we should use w = w\\*sqrt(**2**/n). \n",
    "\n",
    "Those initialization proceses occures on a per-Layer basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,5), activation='relu'),\n",
    "    Dense(32, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bias is a per-Neuron basis -> each neuron has a bias.\n",
    "* Biases are learnable -> changes over epoch iterations.\n",
    "* Bias determines if a neuron is activated -> determine whether or not or by how much a neuron will fire. This let us know when a neuron is meaningfully activated.\n",
    "* Bias increases the flexibility of the model.\n",
    "\n",
    "This works by adding to the input signal a value called bias when executing the activation function.\n",
    "\n",
    "\n",
    "For example, in a Dense Layer, a neuron with a 'relu' activation function will not fire if the sum of its input signals are <=0. With a bias of 1 we can make the node fire with values >-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are parameter that are learned by the network during training (like weight and biases). Those are also called _trainable parameters_.\n",
    "\n",
    "To calculate how many learnable parameter there are in one layer we use: inputs\\*outputs+biases. Whis equals weights+biases. Where outputs = number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable Parameters in a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a convolutional neural network, nodes have more learnable parameters than dense layers as they use **filters** also known as **kernels** or **matrices**.\n",
    "\n",
    "Our total number of learnable parameters:\n",
    "* If previous layer is dense, then input = # of nodes\n",
    "* If previous layer is conv, then input = # of filters\n",
    "* output = (# of filters)\\*(size of filters)\n",
    "* biases = # of filters\n",
    "\n",
    "And we still use: inputs\\*outputs+biases.\n",
    "\n",
    "**Remember:** we must flatten the output of a conv layer when the next layer isn't a conv layer. This means, the next layer will not have # filters as input but image_width\\*image_height*#\\_filters = inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is a technic that helps reduce overfitting or variance in our network by penalizing for complexity.\n",
    "We are trading ability to fit the training data for the ability to generalize better for data it hasn't seen before.\n",
    "\n",
    "To do this we add a term to our loss function that penalizes for large weights. \n",
    "\n",
    "The most commun regularization technic is called the **L2 Regularization**. \n",
    "\n",
    "If we set our regularization parameter to big a big number, the training will tend to have very small weights to keep the loss as small as possible. By doing this we might force the deactivation of some layers thus simplifying our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size is the number of samples that will be passed through the network at one time. Also know as **mini-batch**.\n",
    "\n",
    "For example, with 1000 images, and a batch of 10, we would need 100 to make a full epoch.\n",
    "Generally: the larger the batches, the faster the training but quality of the model may degrade.\n",
    "\n",
    "The batch size is another hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(scalled_train_samples, train_labels, validation_data=valid_set, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very closely linked with the term **Transfer Learning** which occures when we use knowledge that was gained from solving one problem and then apply it to a new related problem.\n",
    "\n",
    "Fine-tuning is a process that takes a model that has already been trained for a given task and then tuning the model to make it perform for a second task assuming the original task is similar to the new task. Using an ANN that has already been trained allows us to take advantage of what the model has already learned without starting from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (batch norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a neural network, we wnat to _normalize_ or _standardize_ our data as part of the pre-processing step.\n",
    "\n",
    "A typical normalization process would be to scale data that are between 10 and 1000 to a range of 0 to 1.\n",
    "A typical standardization process would be to subscract the mean of the dataset to the data point and then divide it by the standard deviation of the dataset. This forces the standardized data to take on a mean of zero and a standard deviation of 1.\n",
    "\n",
    "By using unnormalized/unbalanced data we expose our network to issues like exploding gradiant and it can reduce the training speed.\n",
    "\n",
    "We can also apply batch normalization to layers. The first thing done is normalizing the output of the activation function:\n",
    "1. Normalize output from activation function: z = (x-m)/s\n",
    "2. Multiply normalized output by arbitrary parameter g: z\\*g\n",
    "3. Add arbitraty parameter b to resulting product: (z\\*g)+b\n",
    "\n",
    "All those parameters (m,s,g,b) are trainable parameters since the normalization is included in the gradient process.\n",
    "\n",
    "Those batch normalizations occures on a **per-batch basis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,5), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional parameters that can be added:\n",
    "#   - beta_initializer: Initializer for the beta weight.\n",
    "#   - gamme_initializer: Initializer for the gama weight."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
